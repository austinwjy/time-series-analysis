---
title: "Time series analysis of sales data by statistical methods"
author: "Jiayang Wang"
date: '2021-12-17'
header-includes:
    - \usepackage{setspace}\doublespacing
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,fig.width = 8, fig.height = 4.5)
library(astsa)
```

# Abstract

# Introduction

Time series data is the data collected at different points of time, which is different from cross-sectional data by observing subjucts at one point of time. Time series analysis is the method to obtain useful statistics and information from time series data, which is similar to regression analysis in the purpose of extracing data by exploratory data analysis, modeling and forcasting. Time series data analysis is applied in many fields, including economics, finance, biology, medicine, etc. This report uses a monthly financial data _sales_ of 150 observations taken from Box and Jenkins (1970) in the package _astsa_ to demonstrate the statistical methods of time series data analysis.

# Statistical Methods

## Exploratory data analysis

```{r include = FALSE}
data(sales)
force(sales)
length(sales)
sales<-ts(sales,frequency = 12)
```

```{r}
plot.ts(sales,main="Sales data")
```
Fig. 1. The plot of time series _sales_, which shows a trend of increasing by time, so it is not stationary.

```{r}
acf(sales)
```
Fig. 2. The ACF of time series _sales_. ACF shows a trend of slow decay, meaning there is obvious correlation of different points of time even if time lag is large. So one regular difference is suggested.

```{r}
dsales = diff(sales)
plot.ts(dsales,main="Differenced sales data",ylab="difference")
abline(h=mean(dsales),col="red")
```
Fig. 3. The plot of differenced time series _sales_, which looks stationary since it has constant mean approximately 0.4 and the variance is not changing by time.


```{r}
par(mfrow=c(1,2))
acf(dsales,main="Differenced series sales")
pacf(dsales,main="Differenced series sales")
```

Fig. 4. The ACF and PACF of differenced time series _sales_. The ACF shows no trend of slow decay and no seasonal periodic pattern.

## Modeling

After one differencing, figure 4. shows that ACF cuts off at lag 4, PACF tails off, suggesting _sales_ follows an ARIMA(0,1,4) model. Also, PACF cuts off at lag 2, ACF tails off, suggesting _sales_ follows an ARIMA(2,1,0) model. 

```{r include=FALSE}
sarima(sales,0,1,4)
sarima(sales,2,1,0)
```

# Results

## Model parameter estimates

We define $x_t = \nabla sales$, and use MLE to fit the MA(4) model. When testing the significance of model coefficients, the p-value of ma3 is greater than the significance level of 5%, meaning $\hat{w}_{t-3}$ is not significant, so it is removed from the model. Now we have the following estimated model

$$
\hat{x}_t = 0.413_{(0.182)} + 0.214_{(0.083)}\hat{w}_{t-1}+0.172_{(0.085)}\hat{w}_{t-2}+0.154_{(0.073)}\hat{w}_{t-4}+\hat{w}_t
$$
Where $\hat{\sigma}_w = 1.333$ is on 144 degrees of freedom. The values inside parentheses are the corresponding estimated standard errors. 

The estimated AR(2) model for $\hat{x}_t$ is

$$
\hat{x}_t=0.414_{(0.197)}(1- 0.249)+0.249_{0.080}\hat{x}_{t-1}+0.414_{(0.197)}(1- 0.199)+0.199_{(0.080)}\hat{x}_{t-2}+\hat{w}_t
$$
Where $\hat{\sigma}_w = 1.339$ is on 146 degrees of freedom. All of the parameter estimates are significant.

## Model diagnostics

```{r}
sarima(sales,0,1,4)
```

Fig. 5. Plot of ARIMA(0,1,4) model diagnostics.

```{r}
sarima(sales,2,1,0)
```

Fig. 6. Plot of ARIMA(2,1,0) model diagnostics.

For both models, the standardized residuals plot shows no obvious patterns and constant around 0. The ACF of residuals shows no significant spike, so the residuals are close to white noise. The normal Q-Q plot of standardized residuals shows that the normality assumption holds. The p-values for Ljung-Box statistic are above the significance level of 5%, so we cannot reject the null hypothesis of Ljungâ€“Box test that $\rho(1)=...=\rho(h)$. Thus we say two models pass the model diagonstics and appear to fit well.

## Model selection

MA(4)
$AIC
[1] 3.494997

$AICc
[1] 3.497813

$BIC
[1] 3.615961


AR(2)

$AIC
[1] 3.476962

$AICc
[1] 3.478073

$BIC
[1] 3.557605


|Model|AIC|AICc|BIC|
|-----|---|----|---|
|MA(4)|3.495|3.498|3.616|
|AR(2)|3.477|3.478|3.558|


Table. 1. AIC, AICc, BIC for two fitted models.

We see all of AIC, AICc and BIC of AR(2) model are smaller than MA(4) model, so we choose the ARIMA(2,1,0) model to be the final model.

## Forcasting

```{r}
predict<-sarima.for(sales,10,2,1,0)
data.frame(months_ahead= c(1:10), 
           prediction = predict$pred, lower = predict$pred-qnorm(0.975)*predict$se, 
           upper = predict$pred+qnorm(0.975)*predict$se)
```

Fig. 7. Plot of forcasting _sales_ into the future ten months ahead, where the light grey area is the 95% prediction intervals.

\newpage

|Months ahead|Prediction|Lower bound|Upper bound|
|------------|----------|-----------|-----------|
|1           |263.1325  |260.5077   |265.7573   |
|2           |263.5681  |259.3694   |267.7668   |
|3           |263.9910  |258.2187   |269.7633   |
|4           |264.4114  |257.2370   |271.5859   |
|5           |264.8287  |256.3750   |273.2824   |
|6           |265.2447  |255.6286   |274.8608   |
|7           |265.6597  |254.9772   |276.3423   |
|8           |266.0743  |254.4066   |277.7419   |
|9           |266.4885  |253.9039   |279.0732   |
|10          |266.9026  |253.4585   |280.3467   |

Table 2. Prediction and 95% prediction intervals for each of the ten forecasts.

## Spectral analysis

```{r}
sales.per = mvspec(sales, log="no")
sales.per
table <- sales.per$details[order(sales.per$details[,3], decreasing=TRUE)[1:3],]
table

lower= 2*table[1:3,3]/qchisq(.975,2)
upper = 2*table[1:3,3]/qchisq(.025,2)
cbind(lower,upper)
```

|Frequency|Period|Spectrum|Lower bound|Upper bound|
|---------|------|--------|-----------|-----------|
|0.0133|75|3453.5039|936.193|136406.118|
|0.0067|150|2114.7128|573.267|83526.694|
|0.0333|30|163.1902|44.238|6445.669|

Table. 3. 


